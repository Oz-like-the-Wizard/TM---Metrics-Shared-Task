{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd08bd2b4fd213e88f0d27deee08f39a5a88374bbd03683af29047421dd5d3aea60",
   "display_name": "Python 3.8.2 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "8bd2b4fd213e88f0d27deee08f39a5a88374bbd03683af29047421dd5d3aea60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"/Users/cetiners/Desktop/Corpus/ru-en/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VMD DISTANCE\n",
    "\n",
    "def word_movers_distance(ground_truth, proposed_translation, embedding):\n",
    "\n",
    "    similarities = {}\n",
    "    i = 0\n",
    "\n",
    "    for (tru, tra) in zip(ground_truth,proposed_translation):\n",
    "\n",
    "        ground_truth_tokens = [token for token in tru]\n",
    "        proposed_translation_tokens = [token for token in tra]\n",
    "\n",
    "        similarities[i] = embedding.wmdistance(tru_tokens,tra_tokens)\n",
    "        i =+ 1\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PURE PYTHON IMPLEMENTATION\n",
    "\n",
    "def get_vectors(text):\n",
    "    word = re.compile(r'\\w+')\n",
    "    words = word.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "    \n",
    "def get_similarities(truth, trans):\n",
    "    similarities = {}\n",
    "    for i in range(len(truth)):\n",
    "        vec1 = get_vectors(truth.iloc[i])\n",
    "        vec2 = get_vectors(trans.iloc[i])\n",
    "        cos = get_cosine(vec1,vec2)\n",
    "        similarities[i] = cos\n",
    "    return similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SKLEARN IMPLEMENTATION\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "def get_cosine_sim(truth, trans):\n",
    "    similarities = {}\n",
    "    for i in range(len(truth)):\n",
    "        t1 = truth.iloc[i]\n",
    "        t2 = trans.iloc[i]\n",
    "        tfidf = vectorizer.fit_transform([t1,t2])\n",
    "        similarities[i] = ((tfidf * tfidf.T).A)[0,1]\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cosine_sim(df[\"reference\"],df[\"translation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SCIPY IMPLEMENTATION\n",
    "\n",
    "def cosine_distance_countvectorizer_method(s1, s2):\n",
    "        allsentences = [s1 , s2]\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        from scipy.spatial import distance\n",
    "\n",
    "        vectorizer = CountVectorizer()\n",
    "        all_sentences_to_vector = vectorizer.fit_transform(allsentences)\n",
    "        text_to_vector_v1 = all_sentences_to_vector.toarray()[0].tolist()\n",
    "        text_to_vector_v2 = all_sentences_to_vector.toarray()[1].tolist()\n",
    "\n",
    "        cosine = distance.cosine(text_to_vector_v1, text_to_vector_v2)\n",
    "        cosine_sim = round((1-cosine)*100,2)\n",
    "        return cosine_sim\n",
    "\n",
    "def get_similarities_cvm(truth, trans):\n",
    "    similarities = {}\n",
    "    for i in range(len(truth)):\n",
    "        s1 = truth.iloc[i]\n",
    "        s2 = trans.iloc[i]\n",
    "        similarities[i] = cosine_distance_countvectorizer_method(s1,s2)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "en-fi klasörünü paketliyorum abi'\n",
      "zh-en klasörünü paketliyorum abi'\n",
      "cs-en klasörünü paketliyorum abi'\n",
      "en-zh klasörünü paketliyorum abi'\n",
      "de-en klasörünü paketliyorum abi'\n",
      "ru-en klasörünü paketliyorum abi'\n"
     ]
    }
   ],
   "source": [
    "## GET SIMILARITIES FOR ALL\n",
    "\n",
    "similarities_master = {}\n",
    "\n",
    "for filename in os.listdir(\"/Users/cetiners/Desktop/corpus\"):\n",
    "    if not filename.startswith(\".\"):\n",
    "        print(f\"{filename} klasörünü paketliyorum abi'\")\n",
    "        df = pd.read_csv(f\"/Users/cetiners/Desktop/corpus/{filename}/scores.csv\")\n",
    "        similarities_master[filename] = get_similarities_cvm(df[\"reference\"],df[\"translation\"])\n",
    "\n",
    "final_similarities = pd.DataFrame(similarities_master)\n",
    "\n",
    "#final_similarities.to_excel(\"/Users/cetiners/Desktop/cosine_sim.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       en-fi  zh-en  cs-en  en-zh  de-en  ru-en\n",
       "0      52.22  64.89  76.06    0.0  20.70  52.17\n",
       "1      50.17  76.28  73.03    0.0  75.00  75.79\n",
       "2      42.16  68.02  76.61    0.0  66.67  50.17\n",
       "3      58.83  48.04  62.99   50.0  55.34  65.87\n",
       "4      25.00  47.34  59.67    0.0  78.35  33.81\n",
       "...      ...    ...    ...    ...    ...    ...\n",
       "26414    NaN  73.53    NaN    NaN    NaN    NaN\n",
       "26415    NaN  60.68    NaN    NaN    NaN    NaN\n",
       "26416    NaN  28.57    NaN    NaN    NaN    NaN\n",
       "26417    NaN  33.81    NaN    NaN    NaN    NaN\n",
       "26418    NaN  63.63    NaN    NaN    NaN    NaN\n",
       "\n",
       "[26419 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en-fi</th>\n      <th>zh-en</th>\n      <th>cs-en</th>\n      <th>en-zh</th>\n      <th>de-en</th>\n      <th>ru-en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52.22</td>\n      <td>64.89</td>\n      <td>76.06</td>\n      <td>0.0</td>\n      <td>20.70</td>\n      <td>52.17</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50.17</td>\n      <td>76.28</td>\n      <td>73.03</td>\n      <td>0.0</td>\n      <td>75.00</td>\n      <td>75.79</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42.16</td>\n      <td>68.02</td>\n      <td>76.61</td>\n      <td>0.0</td>\n      <td>66.67</td>\n      <td>50.17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>58.83</td>\n      <td>48.04</td>\n      <td>62.99</td>\n      <td>50.0</td>\n      <td>55.34</td>\n      <td>65.87</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25.00</td>\n      <td>47.34</td>\n      <td>59.67</td>\n      <td>0.0</td>\n      <td>78.35</td>\n      <td>33.81</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26414</th>\n      <td>NaN</td>\n      <td>73.53</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26415</th>\n      <td>NaN</td>\n      <td>60.68</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26416</th>\n      <td>NaN</td>\n      <td>28.57</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26417</th>\n      <td>NaN</td>\n      <td>33.81</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26418</th>\n      <td>NaN</td>\n      <td>63.63</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>26419 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "final_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}